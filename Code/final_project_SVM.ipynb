{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hindu-audience",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "\n",
    "Run the code in this section once, and then run code in the SVM section. The Clean Data section is slow to run, so the outputs are saved as a CSV file to be loaded later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "smooth-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "local-campus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cough</th>\n",
       "      <th>fever</th>\n",
       "      <th>sore_throat</th>\n",
       "      <th>shortness_of_breath</th>\n",
       "      <th>head_ache</th>\n",
       "      <th>corona_result</th>\n",
       "      <th>age_60_and_above</th>\n",
       "      <th>gender</th>\n",
       "      <th>test_indication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278842</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278844</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278845</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contact with confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278847</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274956 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cough  fever  sore_throat  shortness_of_breath  head_ache  \\\n",
       "0         0.0    0.0          0.0                  0.0        0.0   \n",
       "1         1.0    0.0          0.0                  0.0        0.0   \n",
       "2         0.0    1.0          0.0                  0.0        0.0   \n",
       "3         1.0    0.0          0.0                  0.0        0.0   \n",
       "4         1.0    0.0          0.0                  0.0        0.0   \n",
       "...       ...    ...          ...                  ...        ...   \n",
       "278842    0.0    0.0          0.0                  0.0        0.0   \n",
       "278843    0.0    0.0          0.0                  0.0        0.0   \n",
       "278844    0.0    0.0          0.0                  0.0        0.0   \n",
       "278845    0.0    0.0          0.0                  0.0        0.0   \n",
       "278847    0.0    0.0          0.0                  0.0        0.0   \n",
       "\n",
       "       corona_result age_60_and_above  gender         test_indication  \n",
       "0           negative              NaN  female                   Other  \n",
       "1           negative              NaN  female                   Other  \n",
       "2           negative              NaN    male                   Other  \n",
       "3           negative              NaN  female                   Other  \n",
       "4           negative              NaN    male                   Other  \n",
       "...              ...              ...     ...                     ...  \n",
       "278842      negative              NaN     NaN                   Other  \n",
       "278843      negative              NaN     NaN                   Other  \n",
       "278844      negative              NaN     NaN                   Other  \n",
       "278845      positive              NaN     NaN  Contact with confirmed  \n",
       "278847      negative              NaN     NaN                   Other  \n",
       "\n",
       "[274956 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load CSV as pandas dataframe and drop invalid COVID results (Invalid results are listed as 'other')\n",
    "df = pd.read_csv('./Datasets/corona_tested_individuals.csv', low_memory=False, na_values='None')\n",
    "df = df.drop('test_date', axis=1)\n",
    "df.drop(df[df['corona_result'] == 'other'].index, inplace = True) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rolled-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value map to replace text values with numerical values\n",
    "value_map = {\n",
    "    'negative': 0,\n",
    "    'positive': 1,\n",
    "    \n",
    "    'No': 0,\n",
    "    'Yes': 1,\n",
    "    \n",
    "    'male': 0,\n",
    "    'female': 1,\n",
    "    \n",
    "    'Other': 0,\n",
    "    'Contact with confirmed': 1,\n",
    "    'Abroad': 2,\n",
    "    \n",
    "    0: 0,\n",
    "    1: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "romance-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply map to dataframe\n",
    "cols = df.columns\n",
    "for col in cols:\n",
    "    df[col] = df[col].map(value_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "senior-ranking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation Done\n"
     ]
    }
   ],
   "source": [
    "#Impute missing data values\n",
    "labels = df['corona_result'].to_numpy()\n",
    "labels = np.expand_dims(labels, 1)\n",
    "\n",
    "features = df.drop('corona_result', axis=1)\n",
    "features = features.to_numpy()\n",
    "\n",
    "imputer = KNNImputer()\n",
    "imputer.fit(features, labels)\n",
    "features = imputer.transform(features)\n",
    "\n",
    "print(\"Imputation Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adapted-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save imputed data as CSV\n",
    "features = np.round(features, decimals = 0)\n",
    "features = features.astype(int)\n",
    "np.savetxt(\"./Datasets/features_filled.csv\", features, delimiter = ',', fmt = '%d')\n",
    "np.savetxt(\"./Datasets/labels_filled.csv\", labels, delimiter = ',', fmt = '%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-serum",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "necessary-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    features = np.genfromtxt(\"./Datasets/features_filled.csv\", delimiter = ',')\n",
    "    labels = np.genfromtxt(\"./Datasets/labels_filled.csv\", delimiter = ',')\n",
    "    return labels, features\n",
    "\n",
    "def undersample(labels, features, ratio):\n",
    "    positive_labels = np.sum(labels == 1)\n",
    "    negative_labels = np.sum(labels == 0)\n",
    "    positive_labels = int(positive_labels * ratio)\n",
    "\n",
    "    negative_idx = np.where(labels == 0)[0]\n",
    "    negative_idx = np.random.choice(negative_idx, size = negative_labels - positive_labels, replace = False)\n",
    "    features = np.delete(features, negative_idx, axis=0)\n",
    "    labels = np.delete(labels, negative_idx)\n",
    "    \n",
    "    return labels, features\n",
    "\n",
    "def resample(labels, features):\n",
    "    labels, features = sklearn.utils.shuffle(labels, features)\n",
    "    return labels, features\n",
    "\n",
    "def confusion_matrix(labels_predict, labels_test):\n",
    "    TP = np.logical_and(labels_predict == labels_test, labels_test == 1)\n",
    "    TN = np.logical_and(labels_predict == labels_test, labels_test == 0)\n",
    "    FP = np.logical_and(labels_predict != labels_test, labels_test == 0)\n",
    "    FN = np.logical_and(labels_predict != labels_test, labels_test == 1)\n",
    "    \n",
    "    TP = np.sum(TP)\n",
    "    TN = np.sum(TN)\n",
    "    FP = np.sum(FP)\n",
    "    FN = np.sum(FN)\n",
    "    \n",
    "    CM = np.array([[TP, FP], [FN, TN]])\n",
    "    return CM\n",
    "\n",
    "def cross_validate(labels, features, hyperparams, kfold = 10):  \n",
    "    print(\"For hyperparameters: \", hyperparams)\n",
    "    print(\"Fitted fold:\", end = '')\n",
    "    #Separate hyperparameters\n",
    "    undersample_ratio = hyperparams[0]\n",
    "    regularization = hyperparams[1]\n",
    "    gamma = hyperparams[2]\n",
    "\n",
    "    #Remove last few data points to make total number of datapoints divisible by 10\n",
    "    N, D = features.shape\n",
    "    N -= N % kfold;\n",
    "    features = features[0 : N, :]\n",
    "    labels = labels[0 : N]\n",
    "\n",
    "    #Number of data points per fold\n",
    "    step = int(N / kfold)\n",
    "\n",
    "    #Confusion matricies for each fold\n",
    "    confusion_matricies = np.zeros((kfold, 2, 2), dtype = int)\n",
    "\n",
    "    #Run cross-validation\n",
    "    for i in range(kfold):\n",
    "\n",
    "        #Separate data into training and testing\n",
    "        mask = np.ones(N, dtype = bool)\n",
    "        if i == kfold - 1:\n",
    "            mask[i * step :] = False\n",
    "        else:\n",
    "            mask[i * step : (i + 1) * step] = False\n",
    "        features_train = features[mask]\n",
    "        labels_train = labels[mask]\n",
    "        features_test = features[np.invert(mask)]\n",
    "        labels_test = labels[np.invert(mask)]\n",
    "\n",
    "        #Undersample training data\n",
    "        labels_train, features_train = undersample(labels_train, features_train, undersample_ratio)\n",
    "\n",
    "        #Fit SVC\n",
    "        clf = svm.SVC(C = regularization, gamma = gamma)\n",
    "        clf.fit(features_train, labels_train)\n",
    "\n",
    "        #Test on testing data\n",
    "        labels_predict = clf.predict(features_test)\n",
    "\n",
    "        #Get confusion matrix\n",
    "        CM = confusion_matrix(labels_predict, labels_test)\n",
    "        confusion_matricies[i, :, :] = CM\n",
    "\n",
    "        print(\" \" + str(i + 1), end = ''),\n",
    "    print(\"\\n\")\n",
    "    return confusion_matricies\n",
    "    \n",
    "\n",
    "def performance_metric(confusion_matricies, kfold = 10):\n",
    "    CM_avg = np.sum(confusion_matricies, axis = 0) / kfold\n",
    "\n",
    "    TP = CM_avg[0, 0]\n",
    "    FP = CM_avg[0, 1]\n",
    "    FN = CM_avg[1, 0]\n",
    "    TN = CM_avg[1, 1]\n",
    "\n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return CM_avg, np.array([[recall, precision, F1, accuracy]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-candy",
   "metadata": {},
   "source": [
    "## Optimize Undersampling Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "guilty-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For hyperparameters:  [1, 1, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [2, 1, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [3, 1, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [4, 1, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [5, 1, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels, features = load_data()\n",
    "labels, features = resample(labels, features)\n",
    "\n",
    "undersample_ratios = [1, 2, 3, 4, 5]\n",
    "PMs = np.empty((0, 4))\n",
    "for undersample_ratio in undersample_ratios:\n",
    "    hyperparams = [undersample_ratio, 1, 'scale']\n",
    "    CMs = cross_validate(labels, features, hyperparams, kfold = 5)\n",
    "    CM_avg, PM = performance_metric(CMs)\n",
    "    PMs = np.append(PMs, PM, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "hungarian-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79075294 0.33058954 0.466253   0.90301686]\n",
      " [0.73901826 0.47064165 0.57505877 0.94149224]\n",
      " [0.68572204 0.58493079 0.63132892 0.95709843]\n",
      " [0.65462693 0.67834529 0.66627509 0.96487062]\n",
      " [0.65102858 0.69129839 0.67055944 0.96573257]]\n"
     ]
    }
   ],
   "source": [
    "print(PMs)\n",
    "np.savetxt(\"./Datasets/undersampling_hyperparameter.csv\", PMs, delimiter = ',', fmt = '%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-project",
   "metadata": {},
   "source": [
    "# Optimize Regularization Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "weekly-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For hyperparameters:  [4, 1, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [4, 10, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [4, 50, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [4, 100, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [4, 500, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [4, 1000, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n",
      "For hyperparameters:  [4, 5000, 'scale']\n",
      "Fitted fold: 1 2 3 4 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels, features = load_data()\n",
    "labels, features = resample(labels, features)\n",
    "\n",
    "regularizations = [1, 10, 50, 100, 500, 1000, 5000]\n",
    "PMs = np.empty((0, 4))\n",
    "for regularization in regularizations:\n",
    "    hyperparams = [4, regularization, 'scale']\n",
    "    CMs = cross_validate(labels, features, hyperparams, kfold = 5)\n",
    "    CM_avg, PM = performance_metric(CMs)\n",
    "    PMs = np.append(PMs, PM, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "photographic-equation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65483061 0.68008743 0.66722009 0.96500882]\n",
      " [0.65401589 0.68537887 0.66933018 0.96538343]\n",
      " [0.65360853 0.68402728 0.66847203 0.96527068]\n",
      " [0.65666372 0.67645825 0.66641403 0.96478333]\n",
      " [0.65659583 0.67506631 0.66570298 0.96467422]\n",
      " [0.65646004 0.67610657 0.66613848 0.9647506 ]\n",
      " [0.65605269 0.67905833 0.6673573  0.96496518]]\n"
     ]
    }
   ],
   "source": [
    "print(PMs)\n",
    "np.savetxt(\"./Datasets/regularization_hyperparameter.csv\", PMs, delimiter = ',', fmt = '%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-nerve",
   "metadata": {},
   "source": [
    "## Optimize Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ignored-intersection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For hyperparameters:  [5, 1, 1]\n",
      "Fitted fold: 1 2 3 4 5 6 7 8 9 10\n",
      "\n",
      "For hyperparameters:  [5, 1, 10]\n",
      "Fitted fold: 1 2 3 4 5 6 7 8 9 10\n",
      "\n",
      "For hyperparameters:  [5, 1, 50]\n",
      "Fitted fold: 1 2 3 4 5 6 7 8 9 10\n",
      "\n",
      "For hyperparameters:  [5, 1, 100]\n",
      "Fitted fold: 1 2 3 4 5 6 7 8 9 10\n",
      "\n",
      "For hyperparameters:  [5, 1, 200]\n",
      "Fitted fold: 1 2 3 4 5 6 7 8 9 10\n",
      "\n",
      "For hyperparameters:  [5, 1, 500]\n",
      "Fitted fold: 1 2 3 4 5 6 7 8 9 10\n",
      "\n",
      "For hyperparameters:  [5, 1, 1000]\n",
      "Fitted fold: 1 2 3 4 5 6 7 8 9 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels, features = load_data()\n",
    "labels, features = resample(labels, features)\n",
    "\n",
    "gammas = [1, 10, 50, 100, 200, 500, 1000]\n",
    "PMs = np.empty((0, 4))\n",
    "for gamma in gammas:\n",
    "    hyperparams = [5, 1, gamma]\n",
    "    CMs = cross_validate(labels, features, hyperparams)\n",
    "    CM_avg, PM = performance_metric(CMs)\n",
    "    PMs = np.append(PMs, PM, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "worse-nancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65211488 0.68862919 0.66987481 0.96556829]\n",
      " [0.65157173 0.69018339 0.67032199 0.96566648]\n",
      " [0.65292959 0.68800973 0.6700108  0.96554646]\n",
      " [0.65218277 0.68964032 0.67038872 0.96564466]\n",
      " [0.65252224 0.6892076  0.6703634  0.96562284]\n",
      " [0.65340485 0.68742857 0.66998503 0.96551737]\n",
      " [0.65245434 0.68809967 0.6698031  0.96553919]]\n"
     ]
    }
   ],
   "source": [
    "print(PMs)\n",
    "np.savetxt(\"./Datasets/gamma_hyperparameter.csv\", PMs, delimiter = ',', fmt = '%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-colors",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
